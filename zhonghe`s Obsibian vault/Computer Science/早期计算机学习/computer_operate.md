---
title: 操作系统学习
tags:
  - 进程线程协程
  - 冯诺依曼体系
  - 并发与并行
  - 进程调度
  - 进程管理
  - 进程的上下文切换
  - 互斥锁
  - 单线程与多线程
  - 正确的使用锁
---

---
6.cs081os学习

感谢：

参考资料：

https://www.geeksforgeeks.org/pipe-system-call/

很好的文章：

https://swtch.com/~rsc/thread/

同步机制：https://zybtree.github.io/2020/08/12/%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/

参考答案： https://github.com/relaxcn/xv6-labs-2022-solutions/blob/main/doc/utils.md

学习链接： https://pdos.csail.mit.edu/6.828/2021/schedule.html

---

直接从进程与线程入手

#### 进程与线程

单独的CPU变换成多个虚拟的CPU

##### 进程

当网页请求进入的时候 先查看 网页是否在缓存中 如果不是
启动一个磁盘请求用来获取网页  磁盘请求会花费很多时间 等待的过程中会有更多的请求进入
每个进程有它自己的虚拟的CPU 真正的CPU在进程之间来回切换 
需要一些方法例如多个磁盘 模拟控制并发 进程就能发挥作用
来回切换称： 多道程序设计

支持多进程的多道程序系统
一个核一次也只能运行一个进程

![internet.jpg](/study_photo2/operater1.jpg)

---

#### 12.1日

##### 一.进程的并发执行
1. 并发
- 进程的执行是间断的

每个进程的生命周期期间CPU执行 由于某种原因暂停 每个进程执行是间断性的

- 进程的执行速度是不可预测的

进程调度，有其他事件的发生，每个进程上cpu执行坑你一点时间听着再接着运行

2. 共享
- 进程线程之间的制约性
  在一个并发环境下多个进程或者线程之间会共享某些资源，在这些资源的使用过程中会产生进程之间的一种制约性。
比如当一个进程享用打印机这个资源，另外一个进程在第一个进程没有释放这个资源的前提之下就得不到这个资源，那就得等待。

3. 不确定性
- 进程执行的结果与其执行的相对速度有关

进程执行的结果和它的相对执行速度是有关系的，因此在不同的执行顺序的情况下，进程的执行结果也是不确定的。

##### 二.进程互斥
由于各进程要求使用共享资源(变量、文件等)， 而这些资源需要排他性使用，
各进程之间竞争使用这些资源，这一关系称为进程互斥。

- 临界资源
系统中某些资源一次只允许一个进程使用，称这样的资源为临界资源或互斥资源或共享变量。
  这些程序片段，分散在不同的进程里，它们的共同的特点是对同一个共享变量进行一些操作
这一段代码，和另外一个进程的这一段代码互为临界区，互为互斥区

![internet.jpg](/study_photo2/operater2.jpg)

#### 冯诺依曼模型
计算机基本结构：运算器 控制器 存储器 输入设备 输出设备

##### 内存
程序和数据都是存储在内存，存储区域是线性的

存储数据的基本单位是 字节 每一个字节对应一个内存地址

最后一个地址为内存总字节数 -1 结构就像数序中的数据

##### 中央处理器
也就是cpu：
32位cpu一次可以计算4个字节
64位cpu一次可以计算8个字节 位数也就是cpu的位宽 代表cpu一次可以计算的数据量

8 位的 CPU，那么一次只能计算 1 个字节也就是0~255 范围内的数值 那么 32位也就是一次可以计算出 2的32次方这么大的数值
cpu内部组件：寄存器，控制单元和逻辑运算单元

为什么有了内存还需要寄存器？

寄存器种类（通用寄存器）（程序计数器）（指令寄存器）

因为： 内存离 CPU 太远了，而寄存器就在 CPU 里，紧挨着控制单元和逻辑运算单元，自然计算时速度会很快。

###### 总线
总线用于cpu和内存以及其他设备之前的通信

（地址总线）：指定CPU将要操作的内存地址

（数据总线）：用于读写内存的数据

（控制总线）： 发送和接收信号，比如中断，设备复位等信号

CPU 要读写内存数据的时候：

- 首先要通过「地址总线」来指定内存的地址；
- 然后通过「控制总线」控制是读或写命令；
- 最后通过「数据总线」来传输数据；

##### 输入输出设备

输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。
如果输入设备是键盘，按下按键时是需要和 CPU 进行交互的，这时就需要用到控制总线了。

 
##### 线路位宽与CPU位宽
数据是如何通过线路传输的呢 
操作电压，低电压表示 0，高压电压则表示 1

101 二进制数据，十进制则表示 5，如果只有一条线路，就意味着每次只能传递 1 bit 的数据， 那么传输 101 这个数据，就需要 3 次才能传输完成，这样的效率非常低。

增加线路，数据并行传输

CPU 想要操作「内存地址」就需要「地址总线」：

地址总线只有 1 条，那每次只能表示 「0 或 1」这两种地址  最大数量为 2（2^1）个

如果地址总线有 2 条，那么能表示 00、01、10、11 这四种地址  最大数量为 4（2^2）个

CPU 操作 4G 大的内存，那么就需要 32 条地址总线，因为 2 ^ 32 = 4G

CPU位宽最好不要小于线路位宽

##### a little operater systerm

链接 ： https://lwn.net/Articles/250967/

![internet.jpg](/study_photo2/cpumemory.4.png)

所有 CPU（前面的示例中为两个，但可以有更多）都通过公共总线（前端总线，FSB）连接到北桥。除其他外，北桥还包含内存控制器，
其实现决定了计算机使用的 RAM 芯片的类型。不同类型的 RAM，例如 DRAM、Rambus 和 SDRAM，需要不同的内存控制器。

要访问所有其他系统设备，北桥必须与南桥进行通信。南桥通常称为 I/O 桥，通过各种不同的总线处理与设备的通信。如今，PCI、PCI Express、SATA 和 USB 总线最为重要，但南桥也支持 PATA、IEEE 1394、串行和并行端口。
较旧的系统具有连接到北桥的 AGP 插槽。这样做是出于与北桥和南桥之间的连接速度不够快相关的性能原因。然而，如今 PCI-E 插槽全部连接到南桥。


---


让终端显示出自己说的话
```shell
cd ~
root@xiaoxinxiaohao:~# vim .bashrc
root@xiaoxinxiaohao:~# source ~/.bashrc
赵忠鹤闪亮登场
Today is: Fri Dec  6 05:12:09 PM CST 2024
今天也要充满活力哇咔咔

```
---


听从了一些学习的建议，带着问题去读书，想学什么，去书中学，带着问题去读书

---
12.16日

#### 看到了b站的一个关于Go并发设计

了解协程： 协程是一种用户级的轻量级线程。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈

主流语言基本上都选择了多线程作为并发设施

线程相关的概念就是抢占式多任务（Preemptive multitasking），而与协程相关的是协作式多任务

多线程编程是比较困难的， 因为调度程序任何时候都能中断线程， 必须记住保留锁， 去保护程序中重要部分， 防止多线程在执行的过程中断 协程默认会做好全方位保护， 以防止中断


##### 协程相比于多线程的优点
无需系统内核的上下文切换，减小开销； 因为：协程它不像线程和进程那样，需要进行系统内核上的上下文切换，协程的上下文切换是由开发人员决定的

无需原子操作锁定及同步的开销，不用担心资源共享的问题

单线程即可实现高并发，单核 CPU 即便支持上万的协程都不是问题，所以很适合用于高并发处理，尤其是在应用在网络爬虫中

##### 缺点

1. 无法使用 CPU 的多核 因为： 协程的本质是个单线程
2. 写协程就意味着你要一值写一些非阻塞的代码，使用各种异步版本的库，比如后面的异步爬虫教程中用的 aiohttp
3. 
**协程的概念最核心的点其实就是函数或者一段程序能够被挂起（说暂停其实也没啥问题），待会儿再恢复**



## 调度
####  时间片轮转调度


**时间片轮转调度**(**Round-Robin Scheduling**) 是[进程](https://zh.wikipedia.org/wiki/%E8%B0%83%E5%BA%A6_(%E8%AE%A1%E7%AE%97%E6%9C%BA) "调度 (计算机)")和[网络](https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C "计算机网络")调度程序常用的算法之一。) 这一方法将相等长度的[时间片](https://zh.wikipedia.org/wiki/%E6%97%B6%E9%97%B4%E7%89%87 "时间片")按照不变的顺序依次分配给每个进程，且在处理所有进程时不考虑任何[优先级](https://zh.wikipedia.org/wiki/Nice%E5%80%BC "Nice值")。这一算法简单并易于实现，并且不会产生[饥饿问题](https://zh.wikipedia.org/wiki/%E9%A5%A5%E9%A5%BF_(%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F) "饥饿 (操作系统)")。时间片轮转调度可以应用于其他调度问题，例如计算机网络中的数据包调度。它是一个[操作系统](https://zh.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F "操作系统")概念。

该算法的名称来自于其他领域通用的[循环制](https://zh.wikipedia.org/wiki/%E5%BE%AA%E7%92%B0%E5%88%B6 "循环制")原则，即每个参与者轮流获得相同分量的物品

#### 进程调度

了公平地[调度进程](https://zh.wikipedia.org/wiki/%E8%B0%83%E5%BA%A6_(%E8%AE%A1%E7%AE%97%E6%9C%BA) "调度 (计算机)")，循环调度程序通常采用[分时机制](https://zh.wikipedia.org/wiki/%E5%88%86%E6%99%82%E7%B3%BB%E7%B5%B1 "分时系统")，为每个作业分配一个时间片或时间量（CPU 时间），如果用完这一分配的时间还没有完成，则中断该进程。



**多线程编程困难：**

1. **必须保留锁**：为了避免多个线程同时访问同一资源（例如内存、文件、数据库等）时产生冲突，程序员需要使用 **锁（mutex）** 来保护共享资源的访问。锁的目的是确保在同一时间内，只有一个线程可以访问某个关键代码块，防止数据竞争和不一致性。但在实际操作中，锁的使用可能很复杂，程序员需要小心避免死锁、竞争条件等问题。

2. **保护程序的重要部分**：为了保证数据的安全和一致性，在多线程程序中，必须小心标记哪些部分是 **临界区**（critical section），即在并发执行时可能会引发问题的代码区域。开发者必须使用锁（如互斥锁）来保护这些部分，**确保在一个线程执行这段代码时，其他线程不会打断**。


![[时间片轮转调度.png]]

途中描述的过程：
**初始状态**

- **时间 0ms**：进程 P0 到达并占用 CPU，开始执行。
- **时间 50ms**：进程 P1 到达，但必须等待 P0 的时间片到期。

**时间片到期**

- **时间 100ms**：P0 的时间片到期，被操作系统强制中断，P1 开始占用 CPU。此时，P0 被放回队列尾部。

 **新进程到达**

- **时间 130ms**：P2 到达，加入等待队列。
- **时间 190ms**：P3 到达，也加入等待队列。
- **时间 210ms**：P4 到达，加入等待队列。


 **优点**：

- 简单易实现。
- 所有进程公平分配 CPU 资源。
- 时间片长度可调，适应性强。

**缺点**：

- 时间片太短时，会导致频繁的上下文切换，降低效率。
- 时间片太长时，会降低响应速度，不适合交互式系统



---

由于多线程访问共享资源产生的问题： 


引用资源：

https://www.xiaolincoding.com/os/4_process/pessim_and_optimi_lock.html#%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8E%E8%87%AA%E6%97%8B%E9%94%81


### 互斥锁


![[互斥锁 1.png]]


互斥锁加锁失败： 线程会释放CPU 给其他线程 从用户态陷入到内核态，内核帮我们切换线程，简化锁的难度

####  进程的上下文切换

**并发性**：上下文切换是操作系统实现多任务并发执行的基础。即使计算机只有一个 CPU，通过切换线程的上下文，可以让多个线程交替执行，看起来就像是它们在同时运行。

**性能影响**：上下文切换是有开销的，尤其是在频繁发生时，因为它需要保存和加载大量的状态信息。当切换发生时，CPU 的时间被浪费在保存和恢复状态上，而不是执行实际的计算工作。

- **在低并发情况下**，如果线程的计算工作量比较大（例如涉及大量计算或数据处理），那么计算工作的开销通常会远大于上下文切换的开销。上下文切换只是偶尔发生，不会频繁干扰实际计算，因此总体开销较小。
    
- **在高并发情况下**，当线程数量非常多，操作系统频繁进行上下文切换时，上下文切换的开销可能会变得显著。如果上下文切换的频率很高，可能会成为瓶颈，导致系统的整体性能下降。这时，上下文切换的开销可能会比计算工作本身的开销还要大，因为频繁的上下文切换消耗了大量的 CPU 时间，减少了实际计算时间。


**资源占用**：每次上下文切换都会涉及到 CPU 寄存器的保存和恢复，内存管理，甚至可能涉及缓存的丢失，尤其是在线程之间频繁切换时，这些都可能导致性能下降。






---

如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长：

- **锁的使用**： 当多个线程同时访问共享资源时，为了避免数据竞争和不一致的状态，通常需要通过锁来确保同一时刻只有一个线程可以访问资源。这会导致线程在执行临界区（即被锁住的代码）时阻塞，直到锁被释放。
    
- **短时间锁定**： 假设你锁住的代码非常短，例如只是对某个变量进行简单的读取或写入操作，这种情况通常叫做**锁粒度小**。锁的时间很短意味着线程获得锁后，几乎立刻就释放锁，其他线程很快就能获得锁并继续执行。
    
- **上下文切换的成本**： 每当线程被阻塞（如在等待锁的时候），操作系统就需要进行上下文切换。上下文切换的过程包括保存当前线程的状态（比如寄存器、程序计数器等），然后将另一个线程的状态加载到 CPU 中执行。
    
    如果锁住的代码执行时间非常短（比如几微秒），而上下文切换的代价相对较高（可能在毫秒级别），就会发生这样的问题：线程花费了大量的时间等待和切换上下文，而实际执行锁定的代码的时间非常短。每次上下文切换的开销可能比执行锁定的代码要长，这就导致了性能下降。
---

**如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**



### 自旋锁

参考资源： 

https://www.cnblogs.com/cxuanBlog/p/11679883.html

如果持有锁的线程能在短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞状态，它们只需要等一等(自旋)，等到持有锁的线程释放锁之后即可获取，这样就避免了用户进程和内核切换的消耗。


解决上面这种情况一个很好的方式是给**自旋锁设定一个自旋时间**，等时间一到立即释放自旋锁。自旋锁的目的是占着CPU资源不进行释放，等到获取锁立即进行处理。但是**如何去选择自旋时间呢**如果自旋执行时间太长，会有大量的线程处于自旋状态占用 CPU 资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要！JDK在1.6 引入了适应性自旋锁，适应性自旋锁意味着自旋时间不是固定的了，而是由前一次在同一个锁上的自旋时间以及锁拥有的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。




![[自旋锁.png]]

自旋锁加锁失败 线程忙等待 直到它拿到锁

CPU 提供的 `CAS` 函数 在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，会快一些，开销也小一些。

加锁的过程：

- 第一步，查看锁的状态，如果锁是空闲的，则执行第二步；
- 第二步，将锁设置为当前线程持有；


锁失败的线程会  忙等待 「忙等待」可以用 `while` 循环等待实现   

最好是使用 CPU 提供的`PAUSE` 指令来实现「忙等待」

减少循环等待时的耗电量


##### 优点：

占用锁时间非常短的代码块来说性能能大幅度的提升

##### 场景：

但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要 cpu 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁。

---

### 单核cpu工作原理

#### 问题：

在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程） 这句话我怎么理解在单核cpu上时钟中断一个线程运行其他线程？ 这个用图形描绘的话应该怎么描绘，单核cpu如何执行多个任务


这句话的核心意思是，在单核 CPU 上，由于物理上只能同时执行一个线程（因为只有一个 CPU 核心），操作系统需要通过 **抢占式调度** 来模拟并发执行多个任务。具体来说，抢占式调度通过 **时钟中断** 来周期性地中断当前正在执行的线程，然后将 CPU 时间片分配给其他线程。这样，即使在单核 CPU 上，多个线程也可以在看起来几乎是并行地执行。

 **理解“时钟中断”和“抢占式调度”：**

- **时钟中断**：操作系统通过定期的时钟中断来给当前运行的线程“暂停”时间，然后根据调度算法决定是否切换到其他线程。每当时钟中断发生时，操作系统就会停止当前的线程，保存当前的执行状态，然后选择另一个线程来执行。这是抢占式调度的核心机制。
- **抢占式调度**：操作系统主动控制哪个线程可以运行，不会让线程一直占用 CPU。当一个线程的时间片用完或者发生时钟中断时，操作系统会“抢占”当前线程的执行权，切换到另一个线程。

**图形描绘：**

你可以通过一个简单的时间线来表示在单核 CPU 上多个线程的调度过程。

假设我们有 3 个线程：A、B 和 C，且 CPU 每次给一个线程分配 1ms 的时间片。以下是一个简化的调度示意图：

```
时间 -->  | 0ms  | 1ms  | 2ms  | 3ms  | 4ms  | 5ms  | 6ms  | 7ms  | 8ms  | 9ms  |
线程     | A    | B    | A    | C    | A    | B    | A    | C    | B    | A    |
```

**解释：**

1. **0ms - 1ms**：线程 A 开始执行，分配了 1ms 的时间片。
2. **1ms - 2ms**：时钟中断发生，操作系统抢占线程 A，将 CPU 分配给线程 B。
3. **2ms - 3ms**：线程 A 恢复执行。
4. **3ms - 4ms**：时钟中断发生，操作系统抢占线程 A，将 CPU 分配给线程 C。
5. **4ms - 5ms**：线程 A 恢复执行。
6. **5ms - 6ms**：时钟中断发生，操作系统抢占线程 A，将 CPU 分配给线程 B。
7. 以此类推，线程 A、B 和 C 交替执行。

**关键点：**

- **单核 CPU**：由于只有一个核心，实际上在每个时刻只有一个线程在执行。操作系统通过时钟中断来切换不同的线程，使得多个线程交替执行，模拟出并行执行的效果。
- **时间片**：每个线程在 CPU 上的执行时间是有限的。操作系统将时间片（如 1ms 或 10ms）分配给每个线程，每当时间片用完时，操作系统就会通过时钟中断进行上下文切换。
- **上下文切换**：每次时钟中断都会导致一个上下文切换。操作系统需要保存当前线程的状态（如寄存器、栈等），然后加载下一个线程的状态，切换执行。
---


