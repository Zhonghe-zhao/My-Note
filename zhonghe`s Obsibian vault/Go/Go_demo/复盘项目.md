
## 数据库

事务交易

```
-- name: GetAccount :one  
SELECT * FROM accounts  
WHERE id = $1 LIMIT 1;  
  
-- name: GetAccountForUpdate :one  
SELECT * FROM accounts  
WHERE id = $1 LIMIT 1  
*FOR NO KEY UPDATE;*

```

区别

1. `GetAccount`
- 普通查询，只读取数据。
    
- 不加锁，多个事务可以并发读取同一行数据。


1. `GetAccountForUpdate`

- 加了锁，属于 **行级锁**。
    
- `FOR NO KEY UPDATE` 是 `FOR UPDATE` 的弱化版本，只锁定数据行本身，不锁定主键/唯一键。
    
- 阻止其他事务执行 `UPDATE`/`DELETE` 该行，但允许它们执行 `SELECT`。
    
- 常用于事务中，需要修改该行但不改主键的场景，防止并发修改冲突。



- `FOR UPDATE` 会对选中的行加**排他锁（Exclusive Lock）**。
    
- 当第一个事务执行这条语句后，它就**锁住了该行**，直到事务结束。
    
- 第二个事务想对同一行加 `FOR UPDATE` 锁，会发现行已被锁住，所以它**必须等待第一个事务释放锁**



### 锁强度等级（从强到弱）：

1. `FOR UPDATE`：最强，阻止一切修改。
    
2. `FOR NO KEY UPDATE`：略弱，不阻止其他事务更新主键。
    
3. `FOR SHARE`：共享锁，允许读，阻止写。
    
4. `FOR KEY SHARE`：最弱，允许几乎所有操作，主要防止 DELETE。





` docker exec -it postgres12 psql -U root -d simple_bank`  验证事务 各种形式的区别


```sql
// run n concurrent transfer transaction  
for i := 0; i < n; i++ {  
    txName := fmt.Sprintf("tx %d", i+1)  
    go func(i int) {  
       ctx := context.WithValue(context.Background(), txKey, txName)  
       result, err := testStore.TransferTx(ctx, TransferTxParams{  
          FromAccountID: account1.ID,  
          ToAccountID:   account2.ID,  
          Amount:        amount,  
       })  
       errs <- err  
       results <- result  
    }(i)  
}
```

*context.WithValue(context.Background(), txKey, txName)* 用法！


含义是：

- 以 `context.Background()` 为父 context，
    
- 添加一个 key 为 `txKey`，value 为 `txName` 的键值对，
    
- 返回一个新的 `context.Context`（不可变的）。
    

---

###  作用：

这个上下文可以在函数调用链中向下传递数据，例如：

- 传递请求 ID、用户信息、事务对象等
    
- 常用于日志记录、数据库事务传递


`context.WithValue` **不能**用于传递业务数据，只适合传递少量跨中间件所需的数据。




### 排查死锁


```sql
BEGIN;

INSERT INTO transfers (from_account_id,to_account_id,amount) VALUES(1,2,10) RETURNING *;

INSERT INTO entries (account_id,amount) VALUES(1,-10) RETURNING *;
INSERT INTO entries (account_id,amount) VALUES(2,10) RETURNING *;

SELECT * FROM accounts WHERE id = 1 FOR UPDATE;
UPDATE accounts SET balance = 90 WHERE id = 1 RETURNING *;

SELECT * FROM accounts WHERE id = 2 FOR UPDATE;
UPDATE accounts SET balance = 110 WHERE id = 2 RETURNING *;

ROLLBACK
```


当一个表执行插入的时候 另一个表执行select出现了 阻塞！

`答案：因为事务 A **还没提交**，所以插入的数据**对其他事务不可见**，还持有锁。`


(postgres 锁) [https://wiki.postgresql.org/wiki/Lock_Monitoring]


Postgres MVCC 


MVCC，即**多版本并发控制**，是一种用于处理数据库中并发操作的机制。 *在传统的并发控制方式中，常见的做法是通过锁定资源来确保在某一时刻只有一个事务可以修改或读取数据*，以防止数据不一致或冲突。 然而，*传统的锁定机制可能会导致性能瓶颈和并发性下降，尤其在高并发访问的情况下。* MVCC通过引*入多个数据版本来解决传统锁定机制的一些局限性*。 在MVCC中，*每个数据库事务在读取数据时会看到一个特定的版本，这使得事务之间可以同时进行读写操作，而不会相互干扰*。 每个*事务可以操作自己的数据版本，从而实现了更高的并发性和更好的性能。*



执行排查锁的语句

![[MVCC原理.png]]

未提交的 INSERT 会锁住新插入的行，其他事务查询这行时会阻塞，直到提交或回滚。


查找锁


![[寻找sql中的锁.png]]




**外键约束会引发锁冲突**，尤其是在主表（`accounts`）被更新或子表（`transfers`）被插入时。

会导致更新 `accounts.id` 的事务，加锁这个主键行。



 ###  发生阻塞的原理：

1. **外键引用**要求数据库在插入/更新时检查目标行是否存在。
    
2. 为了避免并发过程中误判断（如：主表更新后你还没看到），数据库必须在：
    
    - **子表插入外键引用时锁主表行（共享锁）**
        
    - **主表更新主键时加排他锁**
        
3. 这两个锁互相冲突，**就会导致阻塞**。



### 由外键引发的锁冲突原理

 🏙️ 场景设定：城市银行系统

假设我们有一个银行数据库，有两张表：
- `accounts` (账户表) - 存储所有客户账户
- `transactions` (交易表) - 记录所有转账交易

它们通过外键关联：每笔交易必须关联一个有效的账户ID。

 🚦 外键约束如何工作

外键就像银行的保安，确保：
1. 你不能删除一个还有交易记录的账户（参照完整性）
2. 你不能创建一笔指向不存在账户的交易

 🚗 交通堵塞(锁冲突)是如何发生的

#### 情景1：删除账户时的堵塞
```sql
-- 事务A (银行柜员1)
BEGIN;
DELETE FROM accounts WHERE id = 123; -- 想删除账户123
-- 此时保安(外键)要检查是否有交易关联这个账户
```

同时：
```sql
-- 事务B (银行柜员2)
BEGIN;
INSERT INTO transactions (account_id, amount) VALUES (123, 100); -- 想给账户123新增交易
```

***这时就发生了"交通堵塞"：***
- ***事务A要删除账户123，必须先锁定它，防止新交易加入***
- ***事务B想新增交易到账户123，需要确认账户存在***
- ***两者互相等待，形成死锁***

#### 情景2：转账时的连锁堵塞
```sql
-- 事务A
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 123; -- 从账户123扣款
```

同时：
```sql
-- 事务B
BEGIN;
UPDATE accounts SET balance = balance + 100 WHERE id = 456; -- 向账户456存款
INSERT INTO transactions (from_account, to_account, amount) 
VALUES (123, 456, 100); -- 记录这笔交易
```

这里外键约束需要检查账户123和456是否存在，可能导致锁等待。

 🚑 解决"交通堵塞"的方法

1. **优化事务顺序**：就像调整车流方向
   - 总是按照相同顺序访问表(先accounts后transactions)

2. **减少事务时间**：让车辆快速通过
   - 尽量缩短事务持续时间

3. **使用索引**：增加更多车道
   - 确保外键列有索引

4. **调整隔离级别**：改变交通规则
   - 在某些情况下使用READ COMMITTED而非SERIALIZABLE

5. **批量操作优化**：错峰出行
   - 避免高峰时段(系统繁忙时)执行大批量操作

### 形成死锁

```sql
simple_bank=# INSERT INTO entries (account_id,amount) VALUES(2,10) RETURNING *;
 id | account_id | amount |          created_at
----+------------+--------+-------------------------------
 34 |          2 |     10 | 2025-05-07 09:25:54.744344+00
(1 row)

INSERT 0 1
simple_bank=# INSERT INTO entries (account_id,amount) VALUES(1,-10) RETURNING *;
 id | account_id | amount |          created_at
----+------------+--------+-------------------------------
 35 |          1 |    -10 | 2025-05-07 09:25:54.744344+00
(1 row)

INSERT 0 1
simple_bank=# INSERT INTO entries (account_id,amount) VALUES(2,10) RETURNING *;
 id | account_id | amount |          created_at
----+------------+--------+-------------------------------
 36 |          2 |     10 | 2025-05-07 09:25:54.744344+00
(1 row)

INSERT 0 1
simple_bank=# SELECT * FROM accounts WHERE id =1 FOR UPDATE;
ERROR:  deadlock detected
DETAIL:  Process 90 waits for ShareLock on transaction 651; blocked by process 83.
Process 83 waits for ShareLock on transaction 650; blocked by process 90.
HINT:  See server log for query details.
CONTEXT:  while locking tuple (0,49) in relation "accounts"
```


#### 解答

你这个报错是典型的 **死锁（deadlock）**，下面直接用简单语言解释你这个具体场景发生了什么：

---

 💥 报错信息核心解释：

```txt
ERROR:  deadlock detected
Process 90 等待 651 的 ShareLock，被 83 阻塞；
Process 83 等待 650 的 ShareLock，被 90 阻塞。
```

**两个事务互相持有对方需要的锁，造成死锁，Postgres 自动中止其中一个事务。**

---

 🧠 死锁成因分析：

你执行的是下面两类语句：

```sql
-- 插入 entries（带 account_id 外键），触发对 accounts 表中 id=1、2 的共享锁
INSERT INTO entries (account_id, amount) VALUES (...);

-- 查询 accounts 并 FOR UPDATE（排他锁）
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;
```

---

 🧩 推测发生的步骤如下（两个事务交叉执行）：

 假设：

- **事务 A**：先插入 `account_id = 2` 的 entry
    
- **事务 B**：先插入 `account_id = 1` 的 entry
    

 锁的持有情况：

| 操作                       | 拥有的锁                          | 需要的锁            |
| ------------------------ | ----------------------------- | --------------- |
| 事务 A 插入 entry(2)         | `accounts.id = 2` 的共享锁        | ——              |
| 事务 B 插入 entry(1)         | `accounts.id = 1` 的共享锁        | ——              |
| 事务 A `FOR UPDATE id = 1` | 需要 `accounts.id = 1` 的**排他锁** | 被 B 占用（共享锁）→ 阻塞 |
| 事务 B `FOR UPDATE id = 2` | 需要 `accounts.id = 2` 的**排他锁** | 被 A 占用（共享锁）→ 阻塞 |

就这样，**A 等 B，B 又等 A，死锁形成。**

---

 💡 为什么外键会引发死锁？

因为你的 `entries.account_id` 外键引用 `accounts.id`，插入的时候数据库会：

- 加一个**共享锁**（`ShareLock`）在 `accounts.id` 上，防止它在检查过程中被删或改。
    

但你后面又显式地用 `FOR UPDATE` 想拿 **排他锁**（`ExclusiveLock`）锁 `accounts.id`，两者锁类型不兼容，互相等就容易死锁。

---

 ✅ 解决办法：

 ✅ 方法 1：避免交叉锁顺序

始终按照相同的顺序访问资源（比如先锁 account，再插 entry），比如所有事务都：

1. `FOR UPDATE` 锁定需要的 `accounts`
    
2. 然后插入 `entries`
    

这样可以避免“你拿我需要的，我拿你需要的”。

---
 ✅ 方法 2：插入时使用 `DEFERRABLE INITIALLY DEFERRED` 外键（高级）

延迟外键检查到事务提交时，避免中途加锁，但这个需要创建外键时指定：

```sql
ALTER TABLE entries
ADD CONSTRAINT fk_account
FOREIGN KEY (account_id)
REFERENCES accounts(id)
DEFERRABLE INITIALLY DEFERRED;
```

---

### INSERT INTO entries (account_id, amount) VALUES (...); 为什么会触发共享锁


---

###  原因：PostgreSQL 插入外键时要验证父表行存在

当你执行：

```sql
INSERT INTO entries (account_id, amount) VALUES (1, 100);
```

PostgreSQL 会做两件事：

1. 检查 `accounts` 表中是否有 `id = 1`，防止插入一个无效的外键。
    
2. 为了保证这条 `id = 1` 的 `accounts` 行在检查期间不被其它事务删除或修改 `id`（比如更新或删除），它会在 `accounts.id = 1` 上加一个 **共享锁**。
    

---

###  锁类型说明：

- `FOR UPDATE` 是排他锁（Exclusive Lock），阻止其他读或写。
    
- 插入带外键时，加的是 **共享锁（ShareLock）**，可以并发加多个共享锁，但会阻止别人对该行加排他锁。
    

---

#### 真实例子：

```sql
-- 事务 A
BEGIN;
INSERT INTO entries(account_id, amount) VALUES (1, 100); -- 加共享锁 on accounts.id=1

-- 事务 B
BEGIN;
SELECT * FROM accounts WHERE id = 1 FOR UPDATE; -- 想加排他锁，等不到，共享锁没释放 → 阻塞
```

---


> 插入带外键的数据时，数据库会自动给主表中引用到的行加共享锁，确保这行在事务期间不会被删改，从而保证外键约束不被破坏。

---

### 外键

不是不能用约束（如外键），而是要**清楚它的成本**。外键的**核心优点是数据一致性由数据库保障**，但在**高并发、分布式或事务交错多的系统中，会引发锁竞争甚至死锁**。


####  使用外键的场景：

- 业务简单、读多写少（如 CMS、后台管理系统）
    
- 开发初期，先确保数据一致性，避免程序 bug 写入脏数据
    
- 只有单库或轻量事务，无复杂并发场景
    

####  避免使用外键的场景：

- 高并发写入，比如银行转账、电商下单
    
- 分布式系统，服务之间通过 RPC 协作
    
- 对延迟敏感、锁冲突不能接受

#### 理解外键

`ALTER TABLE "entries" ADD FOREIGN KEY ("account_id") REFERENCES "accounts" ("id");`

"在entries表中，account_id字段的值必须总是存在于accounts表的id字段中"

>**添加外键约束数据库会自动做的事情**

 外键约束深度解析：以银行账户系统为例

这个SQL语句正在为数据库表建立一种父子关系，就像给银行系统添加了一个"账户交易必须真实存在"的规则。让我们彻底理解它的原理和实际影响。
 
 
 ```sql
ALTER TABLE "entries" ADD FOREIGN KEY ("account_id") REFERENCES "accounts" ("id");
```
翻译成自然语言：
"在entries表中，account_id字段的值必须总是存在于accounts表的id字段中"

 🏦 银行系统实例说明

### 表结构
- `accounts`表（父表）：
  ```sql
  CREATE TABLE accounts (
    id BIGSERIAL PRIMARY KEY,
    owner VARCHAR NOT NULL,
    balance DECIMAL NOT NULL
  );
  ```

- `entries`表（子表）：
  ```sql
  CREATE TABLE entries (
    id BIGSERIAL PRIMARY KEY,
    account_id BIGINT NOT NULL,  -- 将要成为外键
    amount DECIMAL NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT now()
  );
  ```

 🛡️ 外键约束的四大守护规则

1. **存在性检查**（INSERT/UPDATE保护）
   ```sql
   -- 会被拒绝（账户999不存在）
   INSERT INTO entries (account_id, amount) VALUES (999, 100);
   -- 错误：insert or update on table "entries" violates foreign key constraint
   ```

2. **防孤儿记录**（DELETE保护）
   ```sql
   -- 当entries表有该账户记录时
   DELETE FROM accounts WHERE id = 1;
   -- 错误：update or delete on table "accounts" violates foreign key constraint
   ```

3. **级联操作**（可选配置）
   ```sql
   -- 可以修改约束使其级联删除
   ALTER TABLE entries 
   ADD CONSTRAINT entries_account_id_fkey 
   FOREIGN KEY (account_id) REFERENCES accounts(id) ON DELETE CASCADE;
   
   -- 现在删除账户会自动删除相关entries
   DELETE FROM accounts WHERE id = 1; -- 自动删除所有account_id=1的entries
   ```

4. **锁行为**（你之前问的核心问题）
   - 当修改accounts表时，会检查entries表 → 可能锁定entries表
   - 当插入entries时，会检查accounts表 → 可能锁定accounts表

#### 建议

- 想追求性能，就别靠数据库帮你兜底，一定要**在业务层控制顺序与并发行为**。
    
- 想快速开发、数据不复杂，就让数据库做这份工作。

***目前并不是很理解 这两个建议***


### 可能是这样


 ####  删除外键后带来的变化：

1.  可以插入一个不存在的 `account_id`：
    
    
    `INSERT INTO entries(account_id, amount) VALUES (9999, 100); -- 不会报错，哪怕 accounts 表根本没有 id=9999`
    
2.  删除 `accounts` 表中的一行，不会阻止：
    
    `DELETE FROM accounts WHERE id = 1; -- 不管 entries 表有没有引用 id=1，照样能删`
    
3.  **关联“逻辑”还在，但数据库不管了**，你只能**靠应用层保证数据一致性**。


### `FOR NO KEY UPDATE` 能缓解冲突

 和外键锁冲突的点：

- 插入外键时会给目标行加 **`FOR KEY SHARE`** 锁；
    
- `FOR UPDATE` 会阻止其他事务加 `FOR KEY SHARE` → 导致死锁；
    
- 而 `FOR NO KEY UPDATE` 不会阻止 `FOR KEY SHARE`；  
    👉 所以就**不会和外键插入冲突，不会死锁！**


示例：

```sql
-- 事务 A：
BEGIN;
SELECT * FROM accounts WHERE id = 1 FOR NO KEY UPDATE;

-- 同时 事务 B：
BEGIN;
INSERT INTO entries(account_id, amount) VALUES (1, 100);
-- ✅ 不阻塞，因为只是加了 KEY SHARE，不影响 NO KEY UPDATE

```



### 为什么要添加FOR UPDATE

在数据库内部，不加锁的SELECT就像"只瞟一眼"数据：

- 看到的数据可能正在被别人修改
    
- 你后续操作可能基于**过时信息**


```sql
-- 危险的不加锁操作！
BEGIN;
SELECT balance FROM accounts WHERE id=1; -- 看到余额500
-- 此时别人可能已经把余额改成400了！
UPDATE accounts SET balance=500-100 WHERE id=1; -- 会错误覆盖别人的修改！
COMMIT;
```



#### KEY的问题

但是我不清楚 为什么FOR UPDATE会造成死锁 但是 FOR NO KEY UPDATE 会避免死锁

想象数据库表就像银行的不同服务窗口：

#### 情况1：`FOR UPDATE` (全功能窗口)

- 你锁定了一个窗口办理"转账+修改个人信息"
    
- 这个窗口**完全被占用**，其他人不能办理任何业务
    
- 如果两个人互相等待对方释放窗口 → **死锁**
    

#### 情况2：`FOR NO KEY UPDATE` (专用业务窗口)

- 你只锁定窗口的"转账"功能
    
- 其他人仍可以用这个窗口办理"查询余额"等不冲突业务
    
- 减少了完全阻塞的情况 → **降低死锁概率**



### 问题 

刚刚我才尝试的时候 开启了两个事务 使用SELECT查询的时候就是使用的普通查询，使用的一系列操作 虽然中间由阻塞但是在一个事务提交之后，总是能获得正确的结果，并没有用到FOR UPDATE等锁


#### 回答：

你虽然没加锁，但数据库用的是 **MVCC + 快照隔离**，**读写分离版本**，所以读操作不会被写阻塞，也不会读到不一致数据（除非降级到 `READ UNCOMMITTED`）。

这也解释了“即使中间有阻塞，最终结果仍然一致”。


#### 还是有问题：

FOR UPDATE 会锁住这行数据，避免其他事务并发更新 balance，防止出现“扣款重叠”。 但是 如果有了数据库的保证，其他事务如果想要更新，不是也会被数据库组织吗

- 数据库确实会在你执行 `UPDATE` 或 `DELETE` 时加 **行锁**，**避免并发写入冲突**；
    
- 如果两个事务并发执行 `UPDATE`，**后提交的事务会阻塞等待锁，甚至可能因为死锁而失败**。


### 冲突可串行化

  什么是“冲突操作”：

两个操作属于冲突，满足以下三个条件：

1. 来自**不同事务**；
    
2. 操作在**同一个数据项**上；
    
3. **至少有一个是写操作**。



---


## 避免死锁

***保证程序始终以一致的顺序获取锁***


```go
if arg.FromAccountID < arg.ToAccountID {  
    result.FromAccount, result.ToAccount, err = addmoney(ctx, q, arg.FromAccountID, -arg.Amount, arg.ToAccountID, arg.Amount)  
  
} else {  
    result.ToAccount, result.ToAccount, err = addmoney(ctx, q, arg.ToAccountID, arg.Amount, arg.FromAccountID, -arg.Amount)  
}
```

 
 *无循环依赖 → 不会死锁。*


- **不要求T1先提交**：只要两者按相同顺序加锁，T2会安全地等待T1释放锁，而不会死锁。
    
- **阻塞是暂时的**：这是数据库的正常行为，属于 **锁等待**（Lock Waiting），而非死锁。
    
- **关键点**：顺序一致性（所有事务按相同顺序加锁）比单个事务的提交时机更重要。


### **2. 循环等待的形成**

1. **事务A** 持有 **锁1**，请求 **锁2**  
    → 发现锁2被事务B持有，**A等待B释放锁2**。
    
2. **事务B** 持有 **锁2**，请求 **锁1**  
    → 发现锁1被事务A持有，**B等待A释放锁1**。



### 隔离级别和读取现象

*isolation levels*   and  *read phenomena.*




### 架构流程图



![[项目架构.png]]




## 职责单一、依赖倒置、封装解耦 


- `token` 目录：可能只负责 JWT 生成和验证，不处理数据库查询。
    
- `mail` 目录：只负责发邮件，不涉及转账逻辑。
    
- `worker` 目录：只消费 Redis 队列任务，不直接修改数据库。



## CI/CD

GithubAction   Jenkins Travis Circleci


工作流程 

JOB1 

JOB2 

JOB3


[Github Action](https://docs.github.com/zh/actions)



## error.go

这个 `error.go` 文件的目的是：

> **对底层数据库的错误进行封装，让你在业务代码中写得更清晰、更安全、更易维护。**


## Viper

从文件或环境变量中读取加载配置

取消代码中的硬编码例如

const （
		
）

 **功能概述**

- **作用**：从指定路径加载配置文件（如 `.env`、`app.yaml` 等），并将其内容解析到 Go 的 `Config` 结构体中。
    
- **特点**：
    
    - 支持多格式配置（环境变量/文件）
        
    - 自动类型转换（如字符串 `"8080"` → 整数 `8080`）
        
    - 环境变量覆盖机制

### app.env


util/condig.go


## Go mock

WHY

使用模拟数据库 避免冲突 测试更快 实现100%覆盖率

1. 实现一个假的数据库

 ✅ Fake DB 优点（手写）

|点|说明|
|---|---|
|🧠 更真实|模拟的逻辑接近真实数据库行为（比如 map 查不到就返回错误）|
|🧪 可用于集成测试|你可以跨多个方法调用（例如转账逻辑中调用多个接口）|
|📦 不依赖 mock 工具|适合初学者和自己写的小项目|
|🔧 可调试|你可以自由加日志、验证逻辑是否走通|

---

 ❌ Fake DB 缺点

|缺点|说明|
|---|---|
|🔁 需要维护逻辑|你要“手动实现”所有接口，比如 Account、Transfer、Entry 这些都要写|
|🧪 容易出 bug|如果你写错逻辑了，测试也会通过，但上线用的 SQLStore 会失败（因为假 Store 不等价）|
|⛓️ 不适合测试边界行为|比如数据库超时、事务回滚、死锁等行为，假 DB 模拟不了|
|👎 不适合多人项目|因为手写 MemStore 没标准，容易变得难以维护|



2. mockgen


| 点           | 说明                             |
| ----------- | ------------------------------ |
| 🧰 自动化      | 直接用命令行 `mockgen` 生成接口的 mock 实现 |
| 🧪 非常适合单元测试 | 精确控制方法返回什么错误、什么值               |
| ✅ 真实行为更抽象   | 比如你可以 mock 出“数据库超时”的错误，测试容错逻辑  |

---

 ❌ mockgen 缺点

|缺点|说明|
|---|---|
|🧠 上手难一点|对初学者不太直观，要理解接口注入、mock 用法|
|🧱 不适合复杂业务|比如一次转账调用多个接口，就得 mock 很多方法，很冗长|
|🕳️ 测不出调用顺序问题|mock 是假的，如果调用参数错了、顺序错了也不会报错（除非加复杂断言）|


修改 `server.go`


```go
package db  
  
import (  
    "context"  
  
    "github.com/jackc/pgx/v5/pgxpool")  
  
// 能够执行数据库的所有功能 以及混合功能  
type Store interface {  
    Querier  
    TransferTx(ctx context.Context, arg TransferTxParams) (TransferTxResult, error)  
    CreateUserTx(ctx context.Context, arg CreateUserTxParams) (CreateUserTxResult, error)  
    VerifyEmailTx(ctx context.Context, arg VerifyEmailTxParams) (VerifyEmailTxResult, error)  
}  
type SQLStore struct {  
    connPool *pgxpool.Pool  
    *Queries  
}  
  
// NewStore creates a new storefunc NewStore(connPool *pgxpool.Pool) Store {  
    return &SQLStore{  
       connPool: connPool,  
       Queries:  New(connPool),   
    }  
}  
  
// SQLStore provides all functions to execute SQL queries and transactions
```






这个 `store.go` 文件的设计思想，是**面向接口编程 + 依赖注入 + 可测试性 + 分层结构**的经典后端架构方案。给你拆解讲明白重点：

---

 ✅ 1. `Store` 是统一入口（**接口定义**）

```go
type Store interface {
	Querier  // 所有单条 SQL 操作（由 SQLC 生成）
	TransferTx(...)   // 一些需要事务的复杂业务逻辑
	CreateUserTx(...)
	VerifyEmailTx(...)
}
```

👉 意思是：

> “我定义一个接口，代表我这个系统对数据库的全部操作。”

好处：

- 外部（例如 HTTP handler）只依赖 `Store`，不关心底层是 PG 还是假数据库。
    
- 方便后期替换（比如搞测试、切换 DB 引擎）
    

---

 ✅ 2. `SQLStore` 是具体实现（**组合 + 实现接口**）

```go
type SQLStore struct {
	connPool *pgxpool.Pool
	*Queries // 嵌入结构体，继承方法
}
```

- `*Queries` 是 SQLC 生成的查询方法（可以直接调用 `GetAccount`, `CreateUser`）
    
- `connPool` 是数据库连接池
    
- `SQLStore` 实现了 `Store` 接口里的所有方法（包括事务方法）
    

---

 ✅ 3. `NewStore(...)` 构造器

```go
func NewStore(connPool *pgxpool.Pool) Store {
	return &SQLStore{...}
}
```

外部只调用 `NewStore()`，不需要知道内部细节（**依赖注入**）

---

 ✅ 4. 为什么还要有 `TransferTx`, `CreateUserTx`

这些是**复杂逻辑**，需要多条 SQL、需要事务控制（commit/rollback）。你不能把这写在 handler 里，所以封装进 `store`：

```go
func (store *SQLStore) TransferTx(...) {
    tx, err := store.connPool.BeginTx(...)
    // 多条查询/更新操作
    tx.Commit()
}
```

---

 ✅ 总结这个文件的设计哲学

| 元素            | 作用                        |
| ------------- | ------------------------- |
| `Store` 接口    | 对所有数据库操作的抽象               |
| `SQLStore`    | 实现接口，具体执行 SQL 操作（封装事务）    |
| `NewStore`    | 构造器，依赖注入，方便测试和替换实现        |
| `TransferTx`等 | 封装复杂业务逻辑，保持 handler 简洁、专注 |

---

这种设计让你：

- 解耦业务逻辑与数据库细节
    
- 测试时可用 `gomock` 替换真实实现
    
- 多人协作时职责清晰

---

## `acount_test.go`

我现在还有一个疑惑在这段代码中

```go


func TestGetAccount(t *testing.T) {

account1 := createRandomAccount(t)

account2, err := testStore.GetAccount(context.Background(), account1.ID)

require.NoError(t, err) //省略了if err!= nil的判断 直接用这个包可以判断错误是否为空

require.NotEmpty(t, account2)

require.Equal(t, account1.ID, account2.ID)

require.Equal(t, account1.Owner, account2.Owner)

require.Equal(t, account1.Balance, account2.Balance)

require.Equal(t, account1.Currency, account2.Currency)

require.WithinDuration(t, account1.CreatedAt, account2.CreatedAt, time.Second)

} 为什么 我在account2, err := testStore.GetAccount(context.Background(), account1.ID)```

 为什么 我在account2, err := testStore.GetAccount(context.Background(), account1.ID)这行中为什么进入到GetAccount中会打入到type Querier interface {}接口中而不是真正的实现呢，



```go
type Store interface {

Querier

TransferTx(ctx context.Context, arg TransferTxParams) (TransferTxResult, error)

CreateUserTx(ctx context.Context, arg CreateUserTxParams) (CreateUserTxResult, error)

VerifyEmailTx(ctx context.Context, arg VerifyEmailTxParams) (VerifyEmailTxResult, error)

}

type SQLStore struct {

connPool *pgxpool.Pool

*Queries

} 如何确保SQLStore实现了 Querier方法呢
```


```go
t.Run(tc.name, func(t *testing.T) {  
    ctrl := gomock.NewController(t)  
    defer ctrl.Finish()  
  
    store := mockdb.NewMockStore(ctrl)  
    tc.buildStubs(store)  
  
    server := newTestServer(t, store)  
    recorder := httptest.NewRecorder()  
  
    url := fmt.Sprintf("/accounts/%d", tc.accountID)  
    request, err := http.NewRequest(http.MethodGet, url, nil)  
    require.NoError(t, err)  
  
    tc.setupAuth(t, request, server.tokenMaker)  
    server.router.ServeHTTP(recorder, request)  
    tc.checkResponse(t, recorder)  
})
```

不太理解这段测试


~~~
为什么一个测试要这么多 什么控制器 创建存储啊 创建测试服务器 创建响应？？ 为什么会有这么多我根本无法想像这些是为什么要创建
~~~


你问得非常关键：**为什么写一个测试要搞这么多对象和逻辑？**  
这正是从“写代码”进阶到“构建可测试的系统”的核心思维转变。我们来一步一步拆开解释：

---
你看到的代码到底在测试什么？

这段代码是在**测试一个 HTTP API 接口**，比如：`GET /accounts/{id}`。它要验证这个接口在不同条件下是否能正确返回响应，比如：

- 用户认证是否成功？
    
- 请求是否能正确路由？
    
- 数据是否能从数据库返回？
    
- 错误是否能被正确处理？
    

---
逐行解释：每一部分在干啥？

 1. `ctrl := gomock.NewController(t)`

创建一个 **mock 控制器**，用于管理 mock 对象的生命周期。`gomock` 需要它来记录 mock 调用和断言。

 2. `store := mockdb.NewMockStore(ctrl)`

用 `gomock` 生成的 `mockStore` 来替代真实的数据库，让你**完全控制数据库的行为**，比如模拟查到了一个账户，或者返回错误等。

---

 3. `tc.buildStubs(store)`

是个函数，会给 mock 设置预期行为。比如：

```go
store.EXPECT().GetAccount(gomock.Any(), gomock.Eq(1)).Return(account, nil)
```

意思是：“如果你传入 ID = 1，就返回我手动造的 account”。

---

 4. `server := newTestServer(t, store)`

创建一个**测试版的 API 服务器**，使用你传入的 `mockStore`，这样可以模拟整个请求过程。

---

5. `request := http.NewRequest(...)`

你写的测试是要模拟 HTTP 请求，因此要构造一个“假的请求”。

---

 6. `tc.setupAuth(...)`

模拟一个用户已经登录的请求，加上 token 或 cookie，不然这个 API 会拒绝访问。

---

7. `server.router.ServeHTTP(recorder, request)`

运行整个请求流程，把请求发给服务器，结果写入 `recorder` 中。

---

8. `tc.checkResponse(t, recorder)`

你会断言返回的响应是否符合预期，比如状态码是 200？body 内容正确？等等。

---

 ✅为什么需要这么复杂？

因为你在做的是**集成测试（或端到端测试）**，它验证的是从：

> HTTP 请求发出 → 路由匹配 → 权限校验 → 数据访问 → 响应返回

这整个链路是否工作。

如果你用真数据库：

- 数据是变的，不可预测
    
- 每次运行测试都得插入清理，很慢
    
- 无法模拟错误场景（比如数据库挂了）
    

所以用 `gomock` 或 `fake store`，你可以完全控制行为，让测试**稳定、快速、灵活**。

---

 💡总结一句话：

> 写测试并不是“写代码的复制品”，而是用模拟+控制的方式，验证系统在各种边界条件下是否能正确运行。

---

要不要我给你画一个这个测试流程的结构图？



---

## 压力测试

`wrk -t4 -c100 -d30s -s post.lua http://192.168.1.110:8080/users`


### 自定义校验器


`validator.go`


```go
var validCurrency validator.Func = func(fieldLevel validator.FieldLevel) bool {  
    if currency, ok := fieldLevel.Field().Interface().(string); ok {  
       return util.IsSupportedCurrency(currency)  
    }  
    return false  
}
```

在gin中注册这个 自定义校验器

```go
if v, ok := binding.Validator.Engine().(*validator.Validate); ok {  
    v.RegisterValidation("currency", validCurrency)  
}
```


## User表

User 是人，Account 是这个人拥有的钱包或银行账户，两者通过 `owner` 建立关系，但本质不是一回事。


## 处理数据库返回的错误


```go
account, err := server.store.CreateAccount(ctx, arg)  
    if err != nil {  
  
       errCode := db.ErrorCode(err)  
       if errCode == db.ForeignKeyViolation || errCode == db.UniqueViolation {  
          ctx.JSON(http.StatusForbidden, errorResponse(err))  
          return  
       }  
       ctx.JSON(http.StatusInternalServerError, errorResponse(err))  
       return  
    }  
    ctx.JSON(http.StatusOK, account)  
}
```

处理数据库错误
返回指定的响应码



## 安全的存储密码！

> bcrypt

1. **自动加盐（Salt）**
    
    - 每次哈希会生成一个随机盐值，即使相同密码，哈希结果也不同，防止彩虹表攻击。
        
    - 例如：
        
        - 密码 `"123456"` → 可能哈希为 `"$2a$10$N9qo8uLOickgx2ZMRZoMy..."`
            
        - 再次哈希 `"123456"` → 结果变成 `"$2a$10$c6C3Qz8kjHxEaGjJlO9Mr..."`



#### 问题

哈希密码加密 既然同样的密码会产生不同的哈希，如果用户第一次的密码哈希值被存入到数据库，下一次用户登录如何比对数据库的哈希值呢


#### 解决

1. **注册时**：
    
    - 系统生成随机盐值
        
    - 将盐值与用户密码组合
        
    - 对组合后的字符串进行哈希
        
    - 将盐值和哈希结果一起存入数据库
        
2. **登录时**：
    
    - 系统从数据库取出该用户的盐值和存储的哈希值
        
    - 将用户输入的密码与存储的盐值组合
        
    - 对组合后的字符串进行相同的哈希运算
        
    - 将新生成的哈希值与数据库存储的哈希值比较



！ 也就是用相同的盐值 


## 增强gomock匹配

gomock.Any()

gomock.eq( )

#### 如何处理哈希值的测试？

自定义匹配器


## token


![[token使用.png]]


#### JWT产生的安全问题


1. 数字签名算法（SSL/TLS）


只有服务器具有签名令牌的私钥


#### 如何保证Token不可伪造：

**技术实现**：

- 服务器用**密钥（Secret Key）**对Token签名（如HMAC-SHA256）。
    
- **客户端拿到Token后只能读取内容，无法修改**（因为不知道密钥，无法生成新签名


##### **如果客户端拿到密钥会怎样？**

- **灾难性后果**：攻击者可以伪造任意Token（比如把自己改成管理员）。
    
- **防护措施**：
    
    1. **永远不要泄露密钥**：禁止硬编码在客户端代码或前端。
        
    2. **密钥轮换**：定期更换密钥（如每月一次），使旧Token失效。
        
    3. **区分环境**：开发、测试、生产环境使用不同密钥。


### 权限逻辑

避免列出不是自己的  其他人账户

避免从操作其他人的银行卡


gin授权api


#### 授权类型

基本认证

令牌认证


OAuth2.0

- **银行典型角色**：
    
    - `customer`：只能操作自己的账户
        
    - `teller`：柜台操作员（部分权限）
        
    - `admin`：管理用户权限\


## go 自定义授权中间件



```go
package api  
  
import (  
    "errors"  
    "fmt"    "net/http"    "strings"  
    "project/simplebank/token"  
    "github.com/gin-gonic/gin")  
  
const (  
    authorizationHeaderKey  = "authorization"  
    authorizationTypeBearer = "bearer"  
    authorizationPayloadKey = "authorization_payload"  
)  
  
// AuthMiddleware creates a gin middleware for authorization  
func authMiddleware(tokenMaker token.Maker) gin.HandlerFunc {  
    return func(ctx *gin.Context) {  
       authorizationHeader := ctx.GetHeader(authorizationHeaderKey)  
  
       if len(authorizationHeader) == 0 {  
          err := errors.New("authorization header is not provided")  
          ctx.AbortWithStatusJSON(http.StatusUnauthorized, errorResponse(err))  
          return  
       }  
  
       fields := strings.Fields(authorizationHeader)  
       if len(fields) < 2 {  
          err := errors.New("invalid authorization header format")  
          ctx.AbortWithStatusJSON(http.StatusUnauthorized, errorResponse(err))  
          return  
       }  
  
       authorizationType := strings.ToLower(fields[0])  
       if authorizationType != authorizationTypeBearer {  
          err := fmt.Errorf("unsupported authorization type %s", authorizationType)  
          ctx.AbortWithStatusJSON(http.StatusUnauthorized, errorResponse(err))  
          return  
       }  
  
       accessToken := fields[1]  
       payload, err := tokenMaker.VerifyToken(accessToken)  
       if err != nil {  
          ctx.AbortWithStatusJSON(http.StatusUnauthorized, errorResponse(err))  
          return  
       }  
  
       ctx.Set(authorizationPayloadKey, payload)  
       ctx.Next()  
    }  
}
```


## go的表驱动测试

(go表驱动测试))[https://learnku.com/go/wikis/61746]



## 路由组


```go
//将路由都换成路由组绑定在一起 组中所有的路由将共享  
authRoutes := router.Group("/").Use(authMiddleware(server.tokenMaker))  
  
authRoutes.GET("/accounts/:id", server.getAccount)  
authRoutes.POST("/accounts", server.createAccount)  
authRoutes.GET("/accounts", server.listAccounts)  
  
authRoutes.POST("transfers", server.createTransfer)  
  
server.router = router
```



## 这一句在做什么

`authPayload := ctx.MustGet(authorizationPayloadKey).(*token.Payload) `

#### 为什么需要类型断言？

### 背景：`gin.Context` 是一个 map，存的东西是 `interface{}` 类型：


`ctx.Set("key", value)           // 存进去的是 interface{} ctx.MustGet("key")             // 取出来的类型是 interface{}`

你取出来之后，如果想访问它的字段，比如 `.Username`，你必须告诉编译器：

> 这个 `interface{}` 实际上是什么类型。

否则你会报错：**“interface does not support field or method Username”**


类型断言是告诉编译器：「我知道从 gin context 里拿出来的是 *token.Payload」，只有这样你才能访问 `.Username` 这样的字段。否则你就只能当成 `interface{}`，啥都不能做。







![[授权规则.png]]


 


## Dockerfiles

定义image 构建应用程序

`docker build -t simplebank:latest .
`

|   |   |
|---|---|
|`docker build`|用 Dockerfile 构建镜像|

|   |   |
|---|---|
|`-t simplebank:latest`|给镜像起个名字叫 `simplebank`，并打上一个 `latest` 标签（tag）|

|   |   |
|---|---|
|`.`|构建上下文：当前目录（包含 Dockerfile 和代码）|


理解镜像和容器

~~~
🛠 镜像是“模板”，容器是“跑起来的程序”

举个例子：

你用下面命令构建了镜像：

`docker build -t simplebank:latest .`

这个镜像就像一个“银行项目的系统镜像文件”。

你再运行：

`docker run -p 8080:8080 simplebank:latest`

就相当于从这个镜像里“开了一台小服务器”，程序运行起来了 —— 这就是一个“容器”。
~~~


这是 **多阶段构建（multi-stage build）**，它能**大幅减少镜像体积**的原因是：**只保留运行时需要的文件，去掉构建阶段产生的临时文件、开发工具、编译器等**。


#### 问题

COPY app.env . 直接这样做是不是会有什么风险，如何避免

`COPY app.env .` 这样做**是有风险的**，特别是当你的 `app.env` 文件中包含敏感信息，比如：

- 数据库用户名密码
    
- JWT 密钥
    
- 第三方服务的 API Key
    
- AWS 密钥等


#### 潜在风险

1. **泄漏到镜像中**：  
    镜像发布到公网（比如 DockerHub）或分享给他人时，这些敏感信息会随镜像一起暴露。
    
2. **版本控制泄漏**：  
    如果你把 `app.env` 提交到了 Git 仓库（尤其是 GitHub），即使删掉了也可能被历史记录保留。




### Docker network

#### 问题

为什么 启动了simplebank容器 也启动了 postgres容器 但是银行容器启动时却说无法连接到数据库！

#### 解决

`DB_SOURCE=postgresql://root:secret@localhost:5432/simple_bank?sslmode=disable`

问题就在localhost 

两个分开的容器  他们没有相同的网络ip地址 

##### **容器IP地址的特性**

- **动态分配**：默认由Docker的虚拟网络（如`bridge`）自动分配（通常为`172.17.0.0/16`网段）。
    
- **隔离性**：仅在容器网络内部有效，外部无法直接访问（除非端口映射）。
    
- **生命周期**：容器重启后IP可能变化（除非指定静态IP）。


##### **容器网络的三种常见模式**

| **网络模式**   | **IP分配方式**     | **外部访问性**         | **典型用途**   |
| ---------- | -------------- | ----------------- | ---------- |
| **bridge** | Docker自动分配（默认） | 需端口映射（`-p 80:80`） | 单机多容器隔离环境  |
| **host**   | 直接使用宿主机IP      | 直接暴露所有端口          | 高性能场景（如压测） |
| **none**   | 无IP（完全隔离）      | 不可访问              | 特殊安全需求     |


理解Dockerfiles docker-compose.yaml  .sh文件的作用！



### grpc

协议缓冲区编译器


Protobuf 同时生成 GRPC 和 HTTP网关代码

`RegisterXXXServer` 是 gRPC 生成的注册函数，必须调用它，gRPC Server 才能知道你实现了什么服务、用哪个结构体来处理请求。

客户端通过简单执行RPC来调用服务器


```go
type SimpleBankClient interface {  
    CreateUser(ctx context.Context, in *CreateUserRequest, opts ...grpc.CallOption) (*CreateUserResponse, error)  
    UpdateUser(ctx context.Context, in *UpdateUserRequest, opts ...grpc.CallOption) (*UpdateUserResponse, error)  
    LoginUser(ctx context.Context, in *LoginUserRequest, opts ...grpc.CallOption) (*LoginUserResponse, error)  
    VerifyEmail(ctx context.Context, in *VerifyEmailRequest, opts ...grpc.CallOption) (*VerifyEmailResponse, error)  
}
```


这是根据grpc生成的接口！  只有实现接口才能成为gRPC server


```go
type SimpleBankServer interface {  
    CreateUser(context.Context, *CreateUserRequest) (*CreateUserResponse, error)  
    UpdateUser(context.Context, *UpdateUserRequest) (*UpdateUserResponse, error)  
    LoginUser(context.Context, *LoginUserRequest) (*LoginUserResponse, error)  
    VerifyEmail(context.Context, *VerifyEmailRequest) (*VerifyEmailResponse, error)  
    mustEmbedUnimplementedSimpleBankServer()  
}  
  
// UnimplementedSimpleBankServer must be embedded to have// forward compatible implementations.  
//  
// NOTE: this should be embedded by value instead of pointer to avoid a nil  
// pointer dereference when methods are called.
```


` mustEmbedUnimplementedSimpleBankServer()  ` 当有方法没有实现时 会返回错误 但是程序可以正常运行！



启动grpc server

#### grpc反射 

如何理解grpc反射的作用

gRPC **反射**的作用可以概括为：

> **允许客户端在不知道 `.proto` 文件的情况下，动态发现服务、方法和消息结构。**


`grpcurl localhost:50051 list`  


### grpc不用绑定参数 http需要为什么


原因：

这是因为：

---

#### ✅ gRPC 不需要绑定参数

gRPC 使用 **Protocol Buffers (protobuf)**，请求数据在网络传输时就是序列化后的二进制格式，**收到数据后直接反序列化为结构体**，不需要再手动解析。

你这样定义 `.proto` 文件：

```proto
message CreateUserRequest {
  string username = 1;
  string password = 2;
}
```

生成后 Go 代码直接是：

```go
func (s *Server) CreateUser(ctx context.Context, req *pb.CreateUserRequest) (*pb.CreateUserResponse, error) {
  req.Username // 直接用
}
```

原因：

- gRPC 自动反序列化请求为 `CreateUserRequest`，你直接拿结构体用。
    
- 不需要类似 Gin 的 `ShouldBindJSON`、`BindQuery` 等。
    

---

#### ❌ HTTP 需要绑定参数

HTTP 协议只是发送 **文本格式（JSON、表单、Query等）**，你需要手动解析（绑定）：

```go
type CreateUserRequest struct {
  Username string `json:"username"`
}

c.ShouldBindJSON(&req) // 手动绑定 JSON -> 结构体
```

原因：

- HTTP 请求体是原始 JSON、表单、url 参数等格式。
    
- 框架（Gin）帮你解析，但你要告诉它“怎么解析” + “往哪儿解析”。
    

---

#### 📌 总结对比

|对比点|gRPC|HTTP|
|---|---|---|
|数据格式|Protobuf（二进制）|JSON（文本）|
|参数绑定|自动反序列化为结构体|需手动绑定（Query、JSON等）|
|代码操作|`req.Username`|先 `Bind` 再用|
|效率|更高（压缩）|较低|

---

#### ✅ 结论

> gRPC 使用 protobuf，天然强类型结构，直接生成结构体；HTTP 是弱类型协议，需要自己解析绑定。